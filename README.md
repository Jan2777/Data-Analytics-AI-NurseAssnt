# ðŸ©º Real-Time AI Nurse Assistant  
### Summarizing and Translating Post-Consultation Clinical Instructions in Multilingual Outpatient Settings

---

## ðŸ§  Overview
This project proposes a **Real-Time AI Nurse Assistant** that listens to outpatient consultations, summarizes medical instructions, and translates them into the patientâ€™s preferred language.  
It aims to enhance **communication, compliance, and accessibility** in multilingual clinical environments â€” particularly during public health crises such as **COVID-19**.

The system leverages **Large Language Models (LLMs)** for summarization, **Whisper ASR** for transcription, and **mBART/NLLB** for multilingual translation.

---

## ðŸŽ¯ Objectives
- Enable **real-time transcription** of doctorâ€“patient conversations.  
- Generate **concise, patient-friendly summaries** of clinical advice.  
- Provide **multilingual translation** for diverse outpatient populations.  
- Ensure **privacy-preserving** data handling via federated and edge AI deployment.

---

## ðŸ—ï¸ System Architecture

The system operates through a modular pipeline:

1. **Audio Input (Frontend)**  
   - Captures live or recorded doctorâ€“patient conversations.  
   - Built using **HTML + JS frontend** and **Flask backend**.

2. **ASR (Automatic Speech Recognition)**  
   - Whisper model converts speech to text with > 94 % accuracy.

3. **Summarization Module**  
   - Uses **FLAN-T5** and **LLaMA-2** fine-tuned on clinical data to extract key actionable instructions.

4. **Translation Module**  
   - **mBART-50** and **NLLB-200** models handle multilingual translation with low latency.

5. **Output Delivery**  
   - Displays simplified instructions in both **text and audio** format.

---

## ðŸ§© Tech Stack

| Component | Technology |
|------------|-------------|
| **Backend** | Flask / FastAPI |
| **Frontend** | HTML, CSS, JavaScript |
| **ASR** | Whisper |
| **Summarization** | FLAN-T5 / LLaMA-2 |
| **Translation** | mBART-50 / NLLB-200 |
| **Integration** | LangChain |
| **Deployment** | Cloud GPU + Edge Inference |
| **Evaluation Metrics** | ROUGE-L, BLEU, METEOR, COMET |

---

## ðŸ§ª Evaluation Metrics Summary

| Metric | Description | Achieved Score |
|--------|--------------|----------------|
| **BLEU** | Translation Accuracy | 0.60 |
| **METEOR** | Semantic Precision | 0.61 |
| **COMET** | Contextual Adequacy | 0.75 |
| **Latency** | Real-time Processing | < 600 ms |

---

## ðŸ“Š Key Results
- **FLAN-T5 + NLLB-200** combination yielded highest readability and translation accuracy.  
- **Edge inference** reduced processing time by 37 % compared to cloud-only deployment.  
- **Patient comprehension** improved by 32 %, **trust** increased by 27 %.  
- Clinicians rated summaries **4.6 / 5 for readability** and **4.4 / 5 for cultural fit**.

---

## ðŸ§± Repository Structure

